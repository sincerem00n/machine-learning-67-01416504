{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "full_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True) # Batch size 64 (adjust as needed)\n",
    "test_loader = DataLoader(test_dataset, batch_size=100, shuffle=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalAutoencoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(ConvolutionalAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),  # Example: 1 input channel (grayscale), 16 output channels\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * 7 * 7, latent_dim),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim , 32 * 7 * 7),\n",
    "            nn.Unflatten(1, (32, 7, 7)),\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1), # Transpose convolution for upsampling\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid()  # Output pixel values between 0 and 1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded,decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  10 Loss:  1.0243024826049805\n",
      "iteration:  20 Loss:  0.8595171570777893\n",
      "iteration:  30 Loss:  0.802959144115448\n",
      "iteration:  40 Loss:  0.7886083722114563\n",
      "iteration:  50 Loss:  0.8005200624465942\n",
      "iteration:  60 Loss:  0.7741352915763855\n",
      "iteration:  70 Loss:  0.7678083181381226\n",
      "iteration:  80 Loss:  0.71996009349823\n",
      "iteration:  90 Loss:  0.7678654193878174\n",
      "iteration:  100 Loss:  0.7205885052680969\n",
      "iteration:  110 Loss:  0.7502965927124023\n",
      "iteration:  120 Loss:  0.6717173457145691\n",
      "iteration:  130 Loss:  0.6911721229553223\n",
      "iteration:  140 Loss:  0.6552340984344482\n",
      "iteration:  150 Loss:  0.6661316156387329\n",
      "iteration:  160 Loss:  0.6115263104438782\n",
      "iteration:  170 Loss:  0.6020353436470032\n",
      "iteration:  180 Loss:  0.5943698287010193\n",
      "iteration:  190 Loss:  0.5878819227218628\n",
      "iteration:  200 Loss:  0.5584214329719543\n",
      "iteration:  210 Loss:  0.5546462535858154\n",
      "iteration:  220 Loss:  0.5818150043487549\n",
      "iteration:  230 Loss:  0.5553558468818665\n",
      "iteration:  240 Loss:  0.5387664437294006\n",
      "iteration:  250 Loss:  0.566636323928833\n",
      "iteration:  260 Loss:  0.5157840251922607\n",
      "iteration:  270 Loss:  0.5086109638214111\n",
      "iteration:  280 Loss:  0.5207952260971069\n",
      "iteration:  290 Loss:  0.5592857599258423\n",
      "iteration:  300 Loss:  0.5322259068489075\n",
      "iteration:  310 Loss:  0.5293765664100647\n",
      "iteration:  320 Loss:  0.543181836605072\n",
      "iteration:  330 Loss:  0.5124590992927551\n",
      "iteration:  340 Loss:  0.5244924426078796\n",
      "iteration:  350 Loss:  0.5380816459655762\n",
      "iteration:  360 Loss:  0.5409936904907227\n",
      "iteration:  370 Loss:  0.5127696394920349\n",
      "iteration:  380 Loss:  0.5160336494445801\n",
      "iteration:  390 Loss:  0.49437496066093445\n",
      "iteration:  400 Loss:  0.5212305188179016\n",
      "iteration:  410 Loss:  0.524586021900177\n",
      "iteration:  420 Loss:  0.5193459987640381\n",
      "iteration:  430 Loss:  0.5082077980041504\n",
      "iteration:  440 Loss:  0.525802493095398\n",
      "iteration:  450 Loss:  0.5203866958618164\n",
      "iteration:  460 Loss:  0.5001602172851562\n",
      "iteration:  470 Loss:  0.4932219088077545\n",
      "iteration:  480 Loss:  0.5007950663566589\n",
      "iteration:  490 Loss:  0.5029923319816589\n",
      "iteration:  500 Loss:  0.5031728744506836\n",
      "iteration:  510 Loss:  0.5389032363891602\n",
      "iteration:  520 Loss:  0.490509033203125\n",
      "iteration:  530 Loss:  0.501105010509491\n",
      "iteration:  540 Loss:  0.5104766488075256\n",
      "iteration:  550 Loss:  0.5153019428253174\n",
      "iteration:  560 Loss:  0.45429715514183044\n",
      "iteration:  570 Loss:  0.5352689623832703\n",
      "iteration:  580 Loss:  0.47903573513031006\n",
      "iteration:  590 Loss:  0.5105128288269043\n",
      "iteration:  600 Loss:  0.47883477807044983\n",
      "iteration:  610 Loss:  0.49063238501548767\n",
      "iteration:  620 Loss:  0.5070094466209412\n",
      "iteration:  630 Loss:  0.4916536808013916\n",
      "iteration:  640 Loss:  0.4803803861141205\n",
      "iteration:  650 Loss:  0.49152135848999023\n",
      "iteration:  660 Loss:  0.5010988712310791\n",
      "iteration:  670 Loss:  0.5035209059715271\n",
      "iteration:  680 Loss:  0.48697569966316223\n",
      "iteration:  690 Loss:  0.4773221015930176\n",
      "iteration:  700 Loss:  0.4845918118953705\n",
      "iteration:  710 Loss:  0.49195465445518494\n",
      "iteration:  720 Loss:  0.4766525626182556\n",
      "iteration:  730 Loss:  0.48910704255104065\n",
      "iteration:  740 Loss:  0.49555501341819763\n",
      "iteration:  750 Loss:  0.48827993869781494\n"
     ]
    }
   ],
   "source": [
    "ae_model = ConvolutionalAutoencoder(latent_dim=64)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(ae_model.parameters(), lr=0.001)\n",
    "\n",
    "epoch = 1\n",
    "for i in range(epoch):\n",
    "    ite = 0\n",
    "    for x,y in train_loader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        _, decoded = ae_model(x)\n",
    "        loss = criterion(decoded, x)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        ite += 1\n",
    "        \n",
    "        if ite % 10 == 0:\n",
    "            print(\"iteration: \", ite , \"Loss: \", float(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120, 100, 64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[  2.1064,   9.5924,  29.5344,  ...,  -1.6584, -11.8681,   0.8876],\n",
       "         [ 10.4090,   4.9620,   5.0505,  ..., -29.4574, -11.1802,  16.3597],\n",
       "         [ 17.4587,  -0.5445,  13.4837,  ..., -12.1434, -20.9418,  13.2182],\n",
       "         ...,\n",
       "         [  9.9296,  -2.0457,   2.3567,  ..., -10.0997,  -2.9495,   3.0960],\n",
       "         [ -2.8685,   6.9513,  16.9549,  ..., -11.4245,   1.6067,  16.2619],\n",
       "         [ -4.4723,  -2.3318,  21.9335,  ...,   6.8050,  -5.7151,   1.4429]],\n",
       "\n",
       "        [[ 12.0254,  13.1583, -33.6256,  ..., -18.7318,   2.7727,  21.2906],\n",
       "         [ -3.4671,  11.5326,   4.2385,  ..., -29.5447, -12.9275,  14.6879],\n",
       "         [  7.2121, -12.4372,  13.8982,  ..., -21.2287,  -0.7825,  10.6011],\n",
       "         ...,\n",
       "         [-10.7555,   9.0414,   3.0773,  ..., -22.2989,   4.6603,   1.2493],\n",
       "         [ -3.7232,   5.4407,   8.8208,  ...,   3.7009, -12.4770,   1.8025],\n",
       "         [  9.3688,  21.1523,  13.4924,  ...,  -7.0173,   4.3205,  10.1362]],\n",
       "\n",
       "        [[ -0.2827,  11.2343, -14.8151,  ...,  -6.7433, -17.2142,  13.9080],\n",
       "         [ -6.9304,  -7.2439,  29.7804,  ...,   2.9303, -31.6126,  -3.7445],\n",
       "         [ -3.1606,  -3.0954,   5.6627,  ..., -22.0131,   9.1078,   7.2935],\n",
       "         ...,\n",
       "         [ 24.9138,  14.2644, -10.5597,  ..., -15.7123, -11.2086,   1.3372],\n",
       "         [ 18.5426,  10.0232,  23.8268,  ...,  -0.5843,  -6.2406,  -3.6706],\n",
       "         [  4.8647,  27.7681,  23.3580,  ...,   2.0036, -19.3934,  13.5534]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-15.1029,  11.3858,  13.6473,  ...,   8.4705, -23.2487, -15.6236],\n",
       "         [ 15.6153,   8.7731,  13.3670,  ...,  -5.5063,  10.1991,  20.4046],\n",
       "         [  4.9174,  -0.3110,  12.0234,  ...,  -7.3212, -24.5053,  -0.9454],\n",
       "         ...,\n",
       "         [ 20.6053,  10.7450,  -6.3354,  ...,  -1.7085,  -0.4350,   8.5658],\n",
       "         [  9.3987,  13.3631,  15.9733,  ..., -19.1230,   1.7613,  28.2154],\n",
       "         [ -7.2710,  14.0136,  15.2053,  ..., -12.0331, -12.1210, -18.4014]],\n",
       "\n",
       "        [[ 17.1424,  11.7473,  10.2354,  ..., -12.5142,   9.1143,  23.7766],\n",
       "         [ 26.8476,   3.2323,  -1.6749,  ..., -12.3875,  -2.6597,   7.8481],\n",
       "         [ 29.9473,  12.8745,   2.2023,  ...,  -0.1447, -29.4786,  14.2328],\n",
       "         ...,\n",
       "         [ 14.5623,  15.0793,  -0.2528,  ..., -15.7663,  -2.0979,   9.7999],\n",
       "         [  2.9563,  -5.3654,   4.7546,  ..., -20.3781,  -8.5604,  10.3958],\n",
       "         [  3.3074,   2.3428,   8.5168,  ..., -18.5693, -12.1592,  11.2438]],\n",
       "\n",
       "        [[ -5.0866,  -7.5509,   6.3932,  ...,  -7.3394, -13.7813, -17.9295],\n",
       "         [ 28.2662,   9.7681, -11.0364,  ...,  -5.1210,  -0.8366,  10.3584],\n",
       "         [ 22.6559,   5.1118,  -1.2684,  ...,  -7.9073,  -3.1164,   4.3712],\n",
       "         ...,\n",
       "         [ 14.0901,   3.1945,   9.3579,  ..., -20.2639, -17.4740,   3.6990],\n",
       "         [-10.0042,   3.1960,  31.3509,  ..., -15.5103, -11.3267,  16.2243],\n",
       "         [ 15.3769,   5.1052,  25.4991,  ..., -15.2668,  -3.4793,  27.6227]]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_model.eval\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = []\n",
    "    for x,y in test_loader:\n",
    "        \n",
    "        encoded, _ = ae_model(x)\n",
    "        out.append(encoded)\n",
    "        \n",
    "out = torch.stack(out)\n",
    "print(out.shape)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_imageProcessing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "full_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=100, shuffle=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalVAE(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(ConvolutionalVAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.flatten = nn.Flatten() # Flatten the output of the convolutional encoder\n",
    "        self.fc_mu = nn.Linear(32 * 7 * 7, latent_dim)  # Adjust the input size based on your image size and encoder layers\n",
    "        self.fc_logvar = nn.Linear(32 * 7 * 7, latent_dim)\n",
    "        self.unflatten = nn.Unflatten(1, (32, 7, 7)) # Unflatten before the decoder\n",
    "        self.linear_decoder = nn.Linear(latent_dim, 32 * 7 * 7) \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden = self.encoder(x)\n",
    "        hidden = self.flatten(hidden) # Flatten for the fully connected layers\n",
    "        mu = self.fc_mu(hidden)\n",
    "        logvar = self.fc_logvar(hidden)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        z = self.linear_decoder(z)\n",
    "        z = self.unflatten(z) # Unflatten before the convolutional decoder\n",
    "        decoded = self.decoder(z)\n",
    "        return decoded, mu, logvar\n",
    "\n",
    "\n",
    "def loss_function(reconstructed_x, x, mu, logvar):\n",
    "    reconstruction_loss = nn.MSELoss()(reconstructed_x, x)\n",
    "    kl_divergence = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return reconstruction_loss + kl_divergence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  10 Loss:  2.7487003803253174\n",
      "iteration:  20 Loss:  1.687086582183838\n",
      "iteration:  30 Loss:  1.3851256370544434\n",
      "iteration:  40 Loss:  1.2362749576568604\n",
      "iteration:  50 Loss:  1.1777422428131104\n",
      "iteration:  60 Loss:  1.1163502931594849\n",
      "iteration:  70 Loss:  1.0577329397201538\n",
      "iteration:  80 Loss:  1.03568696975708\n",
      "iteration:  90 Loss:  1.0474708080291748\n",
      "iteration:  100 Loss:  1.001891016960144\n",
      "iteration:  110 Loss:  0.8907874822616577\n",
      "iteration:  120 Loss:  0.922481894493103\n",
      "iteration:  130 Loss:  0.8945369720458984\n",
      "iteration:  140 Loss:  0.8715651631355286\n",
      "iteration:  150 Loss:  0.8653495907783508\n",
      "iteration:  160 Loss:  0.8826323747634888\n",
      "iteration:  170 Loss:  0.8221346139907837\n",
      "iteration:  180 Loss:  0.8206678628921509\n",
      "iteration:  190 Loss:  0.8077137470245361\n",
      "iteration:  200 Loss:  0.8222501277923584\n",
      "iteration:  210 Loss:  0.8674689531326294\n",
      "iteration:  220 Loss:  0.8041913509368896\n",
      "iteration:  230 Loss:  0.8080997467041016\n",
      "iteration:  240 Loss:  0.7551628351211548\n",
      "iteration:  250 Loss:  0.8284400701522827\n",
      "iteration:  260 Loss:  0.8434309959411621\n",
      "iteration:  270 Loss:  0.8516451120376587\n",
      "iteration:  280 Loss:  0.7774635553359985\n",
      "iteration:  290 Loss:  0.8257327079772949\n",
      "iteration:  300 Loss:  0.7735347747802734\n",
      "iteration:  310 Loss:  0.8141019940376282\n",
      "iteration:  320 Loss:  0.861015260219574\n",
      "iteration:  330 Loss:  0.7974692583084106\n",
      "iteration:  340 Loss:  0.7779778242111206\n",
      "iteration:  350 Loss:  0.815118670463562\n",
      "iteration:  360 Loss:  0.8175475597381592\n",
      "iteration:  370 Loss:  0.8395538926124573\n",
      "iteration:  380 Loss:  0.8157987594604492\n",
      "iteration:  390 Loss:  0.8416323065757751\n",
      "iteration:  400 Loss:  0.8144136071205139\n",
      "iteration:  410 Loss:  0.8607863187789917\n",
      "iteration:  420 Loss:  0.8052232265472412\n",
      "iteration:  430 Loss:  0.8052161931991577\n",
      "iteration:  440 Loss:  0.8040953874588013\n",
      "iteration:  450 Loss:  0.7958486080169678\n",
      "iteration:  460 Loss:  0.8107746839523315\n",
      "iteration:  470 Loss:  0.7744666934013367\n",
      "iteration:  480 Loss:  0.7767720222473145\n",
      "iteration:  490 Loss:  0.8016359806060791\n",
      "iteration:  500 Loss:  0.8582764267921448\n",
      "iteration:  510 Loss:  0.7812528610229492\n",
      "iteration:  520 Loss:  0.7732300758361816\n",
      "iteration:  530 Loss:  0.8109378814697266\n",
      "iteration:  540 Loss:  0.8148545026779175\n",
      "iteration:  550 Loss:  0.8000345230102539\n",
      "iteration:  560 Loss:  0.7921397686004639\n",
      "iteration:  570 Loss:  0.7820484638214111\n",
      "iteration:  580 Loss:  0.823607861995697\n",
      "iteration:  590 Loss:  0.7701807022094727\n",
      "iteration:  600 Loss:  0.7536591291427612\n",
      "iteration:  610 Loss:  0.811846137046814\n",
      "iteration:  620 Loss:  0.8200681209564209\n",
      "iteration:  630 Loss:  0.7798404097557068\n",
      "iteration:  640 Loss:  0.7953379154205322\n",
      "iteration:  650 Loss:  0.799957275390625\n",
      "iteration:  660 Loss:  0.8233727812767029\n",
      "iteration:  670 Loss:  0.8170673847198486\n",
      "iteration:  680 Loss:  0.8135873079299927\n",
      "iteration:  690 Loss:  0.8546861410140991\n",
      "iteration:  700 Loss:  0.7965914607048035\n",
      "iteration:  710 Loss:  0.7928338050842285\n",
      "iteration:  720 Loss:  0.8029686212539673\n",
      "iteration:  730 Loss:  0.8226457834243774\n",
      "iteration:  740 Loss:  0.8303191661834717\n",
      "iteration:  750 Loss:  0.8383328914642334\n"
     ]
    }
   ],
   "source": [
    "vae_model = ConvolutionalVAE(latent_dim = 64)\n",
    "optimizer = torch.optim.Adam(vae_model.parameters(), lr=0.001)\n",
    "\n",
    "epoch = 1\n",
    "for i in range(epoch):\n",
    "    ite = 0\n",
    "    for x,y in train_loader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs, mu, logvar  = vae_model(x)\n",
    "        loss = loss_function(outputs, x, mu, logvar)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        ite += 1\n",
    "        \n",
    "        if ite % 10 == 0:\n",
    "            print(\"iteration: \", ite , \"Loss: \", float(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120, 100, 64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.7620e-05, -3.5650e-06,  4.9145e-05,  ...,  5.9949e-07,\n",
       "          -1.5809e-05,  1.8803e-05],\n",
       "         [-2.7620e-05, -3.5650e-06,  4.9145e-05,  ...,  5.9949e-07,\n",
       "          -1.5809e-05,  1.8803e-05],\n",
       "         [-7.0616e-04, -2.5848e-04,  3.9620e-04,  ..., -8.5785e-04,\n",
       "          -6.0410e-04,  8.6610e-04],\n",
       "         ...,\n",
       "         [-2.7620e-05, -3.5650e-06,  4.9145e-05,  ...,  5.9949e-07,\n",
       "          -1.5809e-05,  1.8803e-05],\n",
       "         [-2.7620e-05, -3.5650e-06,  4.9145e-05,  ...,  5.9949e-07,\n",
       "          -1.5809e-05,  1.8803e-05],\n",
       "         [-2.7620e-05, -3.5650e-06,  4.9145e-05,  ...,  5.9949e-07,\n",
       "          -1.5809e-05,  1.8803e-05]],\n",
       "\n",
       "        [[-2.7620e-05, -3.5650e-06,  4.9145e-05,  ...,  5.9949e-07,\n",
       "          -1.5809e-05,  1.8803e-05],\n",
       "         [-2.7620e-05, -3.5650e-06,  4.9145e-05,  ...,  5.9949e-07,\n",
       "          -1.5809e-05,  1.8803e-05],\n",
       "         [-2.1464e-05, -2.9758e-05,  1.0743e-04,  ..., -6.2523e-05,\n",
       "          -5.3479e-05,  2.8218e-05],\n",
       "         ...,\n",
       "         [-2.7620e-05, -3.5650e-06,  4.9145e-05,  ...,  5.9949e-07,\n",
       "          -1.5809e-05,  1.8803e-05],\n",
       "         [-2.7620e-05, -3.5650e-06,  4.9145e-05,  ...,  5.9949e-07,\n",
       "          -1.5809e-05,  1.8803e-05],\n",
       "         [-2.7620e-05, -3.5650e-06,  4.9145e-05,  ...,  5.9949e-07,\n",
       "          -1.5809e-05,  1.8803e-05]],\n",
       "\n",
       "        [[-2.7620e-05, -3.5650e-06,  4.9145e-05,  ...,  5.9949e-07,\n",
       "          -1.5809e-05,  1.8803e-05],\n",
       "         [-2.7620e-05, -3.5650e-06,  4.9145e-05,  ...,  5.9949e-07,\n",
       "          -1.5809e-05,  1.8803e-05],\n",
       "         [-2.7620e-05, -3.5650e-06,  4.9145e-05,  ...,  5.9949e-07,\n",
       "          -1.5809e-05,  1.8803e-05],\n",
       "         ...,\n",
       "         [-2.7620e-05, -3.5650e-06,  4.9145e-05,  ...,  5.9949e-07,\n",
       "          -1.5809e-05,  1.8803e-05],\n",
       "         [-2.7620e-05, -3.5650e-06,  4.9145e-05,  ...,  5.9949e-07,\n",
       "          -1.5809e-05,  1.8803e-05],\n",
       "         [-2.7620e-05, -3.5650e-06,  4.9145e-05,  ...,  5.9949e-07,\n",
       "          -1.5809e-05,  1.8803e-05]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.7620e-05, -3.5650e-06,  4.9145e-05,  ...,  5.9949e-07,\n",
       "          -1.5809e-05,  1.8803e-05],\n",
       "         [-2.7620e-05, -3.5650e-06,  4.9145e-05,  ...,  5.9949e-07,\n",
       "          -1.5809e-05,  1.8803e-05],\n",
       "         [-1.9252e-04, -1.6009e-04, -2.3786e-04,  ..., -2.0607e-04,\n",
       "          -9.9655e-05, -1.0319e-04],\n",
       "         ...,\n",
       "         [-2.7620e-05, -3.5650e-06,  4.9145e-05,  ...,  5.9949e-07,\n",
       "          -1.5809e-05,  1.8803e-05],\n",
       "         [-4.3198e-04,  3.8216e-04,  5.6877e-04,  ...,  6.6076e-04,\n",
       "          -7.0990e-04,  1.1979e-03],\n",
       "         [-2.7620e-05, -3.5650e-06,  4.9145e-05,  ...,  5.9949e-07,\n",
       "          -1.5809e-05,  1.8803e-05]],\n",
       "\n",
       "        [[-2.7620e-05, -3.5650e-06,  4.9145e-05,  ...,  5.9949e-07,\n",
       "          -1.5809e-05,  1.8803e-05],\n",
       "         [ 8.6868e-05, -3.8750e-04,  8.2177e-04,  ...,  2.2510e-04,\n",
       "          -4.8651e-04, -3.0806e-04],\n",
       "         [-7.1377e-04, -6.5486e-04, -1.1451e-03,  ..., -8.5937e-04,\n",
       "          -3.6470e-04, -4.8879e-04],\n",
       "         ...,\n",
       "         [-2.7620e-05, -3.5650e-06,  4.9145e-05,  ...,  5.9949e-07,\n",
       "          -1.5809e-05,  1.8803e-05],\n",
       "         [-2.7620e-05, -3.5650e-06,  4.9145e-05,  ...,  5.9949e-07,\n",
       "          -1.5809e-05,  1.8803e-05],\n",
       "         [-2.7620e-05, -3.5650e-06,  4.9145e-05,  ...,  5.9949e-07,\n",
       "          -1.5809e-05,  1.8803e-05]],\n",
       "\n",
       "        [[-2.7620e-05, -3.5650e-06,  4.9145e-05,  ...,  5.9949e-07,\n",
       "          -1.5809e-05,  1.8803e-05],\n",
       "         [-2.7620e-05, -3.5650e-06,  4.9145e-05,  ...,  5.9949e-07,\n",
       "          -1.5809e-05,  1.8803e-05],\n",
       "         [-2.7620e-05, -3.5650e-06,  4.9145e-05,  ...,  5.9949e-07,\n",
       "          -1.5809e-05,  1.8803e-05],\n",
       "         ...,\n",
       "         [-2.7620e-05, -3.5650e-06,  4.9145e-05,  ...,  5.9949e-07,\n",
       "          -1.5809e-05,  1.8803e-05],\n",
       "         [-2.7620e-05, -3.5650e-06,  4.9145e-05,  ...,  5.9949e-07,\n",
       "          -1.5809e-05,  1.8803e-05],\n",
       "         [ 1.6306e-04,  1.1368e-05, -1.4758e-04,  ...,  3.3082e-04,\n",
       "           1.4652e-05, -2.5470e-04]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae_model.eval\n",
    "\n",
    "with torch.no_grad():\n",
    "    mu_list = []\n",
    "    logvar_list = []\n",
    "    for x,y in test_loader:\n",
    "        \n",
    "        _, mu, logvar = vae_model(x)\n",
    "        mu_list.append(mu)\n",
    "        logvar_list.append(logvar)\n",
    "\n",
    "logvar_list = torch.stack(logvar_list)     \n",
    "mu_list = torch.stack(mu_list)\n",
    "print(mu_list.shape)\n",
    "mu_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_imageProcessing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
